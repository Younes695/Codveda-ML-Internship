{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eabe7160-ed8c-4c21-8f25-8bc71c097ed3",
   "metadata": {},
   "source": [
    "# Task 1: Data Preprocessing\n",
    "### Level 1 - Machine Learning Internship\n",
    "\n",
    "**Objective:**\n",
    "The goal of this task is to prepare the \"House Prediction Dataset\" for machine learning. This involves:\n",
    "1. Loading the dataset.\n",
    "2. Handling missing values.\n",
    "3. Splitting the data into training and testing sets.\n",
    "4. Feature Scaling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f6bf7201-01a2-4c7c-8dc6-bebba788f462",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries Imported Successfully!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "print(\"Libraries Imported Successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5fc0a117-0d72-425c-a399-e8192bfc1b79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 rows of the dataset:\n",
      "        0     1     2   3      4      5     6       7   8      9     10  \\\n",
      "0  0.00632  18.0  2.31   0  0.538  6.575  65.2  4.0900   1  296.0  15.3   \n",
      "1  0.02731   0.0  7.07   0  0.469  6.421  78.9  4.9671   2  242.0  17.8   \n",
      "2  0.02729   0.0  7.07   0  0.469  7.185  61.1  4.9671   2  242.0  17.8   \n",
      "3  0.03237   0.0  2.18   0  0.458  6.998  45.8  6.0622   3  222.0  18.7   \n",
      "4  0.06905   0.0  2.18   0  0.458  7.147  54.2  6.0622   3  222.0  18.7   \n",
      "\n",
      "       11    12    13  \n",
      "0  396.90  4.98  24.0  \n",
      "1  396.90  9.14  21.6  \n",
      "2  392.83  4.03  34.7  \n",
      "3  394.63  2.94  33.4  \n",
      "4  396.90  5.33  36.2  \n",
      "\n",
      "Dataset Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 506 entries, 0 to 505\n",
      "Data columns (total 14 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   0       506 non-null    float64\n",
      " 1   1       506 non-null    float64\n",
      " 2   2       506 non-null    float64\n",
      " 3   3       506 non-null    int64  \n",
      " 4   4       506 non-null    float64\n",
      " 5   5       506 non-null    float64\n",
      " 6   6       506 non-null    float64\n",
      " 7   7       506 non-null    float64\n",
      " 8   8       506 non-null    int64  \n",
      " 9   9       506 non-null    float64\n",
      " 10  10      506 non-null    float64\n",
      " 11  11      506 non-null    float64\n",
      " 12  12      506 non-null    float64\n",
      " 13  13      506 non-null    float64\n",
      "dtypes: float64(12), int64(2)\n",
      "memory usage: 55.5 KB\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\EgyTech\\AppData\\Local\\Temp\\ipykernel_15804\\614597780.py:3: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  df = pd.read_csv('4) house Prediction Data Set.csv',\n"
     ]
    }
   ],
   "source": [
    "# 1. Loading Dataset\n",
    "# Dataset has whitespace delimiters & bo header\n",
    "df = pd.read_csv('4) house Prediction Data Set.csv',\n",
    "                 delim_whitespace=True,\n",
    "                 header=None)\n",
    "# Display first 5 rows\n",
    "print(\"First 5 rows of the dataset:\")\n",
    "print(df.head())\n",
    "\n",
    "# Dataset Information\n",
    "print(\"\\nDataset Info:\")\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eeba812b-0b39-4906-9593-ec90fbf1e608",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values handled. X shape: (506, 13)\n"
     ]
    }
   ],
   "source": [
    "# 2. Handling Missing Values\n",
    "X = df.iloc[:, :-1].values # Features\n",
    "y = df.iloc[:, -1].values  # Target\n",
    "\n",
    "# Using SimpleImputer to replace missing values with the mean\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X = imputer.fit_transform(X)\n",
    "\n",
    "print(f\"Missing values handled. X shape: {X.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f91c18c1-8401-4bf4-8185-bd8b79be6790",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Shape: (404, 13)\n",
      "Testing Data Shape: (102, 13)\n"
     ]
    }
   ],
   "source": [
    "# 3. Splitting the Dataset\n",
    "# 80% Training, 20% Testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Training Data Shape: {X_train.shape}\")\n",
    "print(f\"Testing Data Shape: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4dfcdeff-1e03-4139-8b59-7a08218ae546",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Preprocessing Completed Successfully!\n",
      "First 5 rows of X_train_scaled:\n",
      " [[ 1.28770177 -0.50032012  1.03323679 -0.27808871  0.48925206 -1.42806858\n",
      "   1.02801516 -0.80217296  1.70689143  1.57843444  0.84534281 -0.07433689\n",
      "   1.75350503]\n",
      " [-0.33638447 -0.50032012 -0.41315956 -0.27808871 -0.15723342 -0.68008655\n",
      "  -0.43119908  0.32434893 -0.62435988 -0.58464788  1.20474139  0.4301838\n",
      "  -0.5614742 ]\n",
      " [-0.40325332  1.01327135 -0.71521823 -0.27808871 -1.00872286 -0.40206304\n",
      "  -1.6185989   1.3306972  -0.97404758 -0.60272378 -0.63717631  0.06529747\n",
      "  -0.65159505]\n",
      " [ 0.38822983 -0.50032012  1.03323679 -0.27808871  0.48925206 -0.30045039\n",
      "   0.59168149 -0.8392398   1.70689143  1.57843444  0.84534281 -3.86819251\n",
      "   1.52538664]\n",
      " [-0.32528234 -0.50032012 -0.41315956 -0.27808871 -0.15723342 -0.83109424\n",
      "   0.03374663 -0.00549428 -0.62435988 -0.58464788  1.20474139  0.3791194\n",
      "  -0.16578736]]\n"
     ]
    }
   ],
   "source": [
    "# 4. Feature Scaling\n",
    "# Standardization is crucial for regression models\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit on training set only, then transform both\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(\"Data Preprocessing Completed Successfully!\")\n",
    "print(f\"First 5 rows of X_train_scaled:\\n {X_train_scaled[:5]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
